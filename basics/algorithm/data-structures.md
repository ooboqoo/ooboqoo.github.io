# 数据结构

## 数组

数组可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。

### 如何实现随机访问

**数组 Array** 是一种 *线性表* 数据结构。它用一组 *连续的内存空间* ，来存储一组具有 *相同类型* 的数据。数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

顾名思义，**线性表** 就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。而与之相对的是 **非线性表**，如二叉树、堆、图等。在非线性表中，数据之间并不是简单的前后关系。

数组有两个限制：连续的内存空间和相同类型的数据。正是因为这两个限制，才有了一个堪称杀手锏的特性：*随机访问*。但有利就有弊，这两个限制导致数组的很多操作变得非常低效，如删除或插入一个数据，为了保证连续性，需要做大量的数据搬移工作。

从数组存储的内存模型上来看，**下标** 最确切的定义应该是 **偏移(offset)**。如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：

```txt
a[k]_address = base_address + k * type_size。
```

### 低效的插入、删除操作

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。

但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，可以直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

```txt
// 当元素顺序无关紧要时，在数组中的某个位置插入一个元素的快捷方法 (想说这个时候不应该是 Set 么)
{a, b, c, d, e}  -- 在 a[2] 插入 x --> {a, b, x, d, e, c}
```

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了保证内存的连续性，也需要搬移数据。在某些特殊场景下，我们并不一定非得追求数组中数据的(实时)连续性。我们可以先记录下已经删除的数据，每次删除并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？



### 数组的访问越界问题

我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。这种情况下，一般都会出现莫名其妙的逻辑错误，debug 的难度非常的大。很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统。

如果你是 Java 工程师，几乎天天都在用 `ArrayList`。那它和数组相比，到底有哪些优势呢？如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。
1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 `Object[][] array`；而用容器的话则需要这样定义：`ArrayList<ArrayList<object>> array`。

总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。


## 链表

我们先来讨论一个经典的链表应用场景，那就是 LRU 缓存淘汰算法。

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。

数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。

链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、循环链表和双向链表。

我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的 **结点**。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作 **后继指针 next**。从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作 **头结点**，把最后一个结点叫作 **尾结点**。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个 **空地址 NULL**，表示这是链表上最后一个结点。与数组一样，链表也支持数据的查找、插入和删除操作。


**循环链表** 是一种特殊的单链表。它跟单链表唯一的区别就在尾结点。循环链表的尾结点指针指向链表的头结点。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。如著名的约瑟夫问题，尽管用单链表也可以实现，但是用循环链表代码会简洁很多。

单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而 **双向链表**，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个 **前驱指针 prev** 指向前面的结点。

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛。如果你熟悉 Java 语言，你肯定用过 `LinkedHashMap` 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。实际上，这里有一个更加重要的知识点需要你掌握，那就是 *用空间换时间* 的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用 *以时间换空间* 的设计思路。

### 如何写出正确的链表代码

* 理解指针或引用的含义
* 警惕指针丢失和内存泄漏
* 利用哨兵简化实现难度
* 重点留意 *边界条件* 处理
* 举例画图，辅助思考
* 多写多练，没有捷径

哨兵应用示例

```c
// 在数组 array 中查找 x 的位置，其中 n 为数组的长度
int find1(int array[], int n, int x) {
  int i = 0;
  while (i < n) {
    if (array[i] == x) return i;
    i++;
  }
  return -1;
}

// 利用哨兵再循环内部省掉了一个判断语句，当 n 很大时这个优化的效果就很客观了
int find2(int array[], int n, int x) {
  int i = 0;
  if (array[n - 1] == x) return n - 1;
  array[n - 1] = x;           // 设置哨兵，确保下面的 while 语句不会出现死循环
  while (array[i] != x) i++;  // 因为上一步设置了哨兵，所以可以省掉一个 i < n 的判断
  return i == n - 1 ? -1 : i;
}
```

软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下能否正确运行。我经常用来检查链表代码是否正确的边界条件有这样几个：
* 如果链表为空时，代码是否能正常工作？
* 如果链表只包含一个结点时，代码是否能正常工作？
* 如果链表只包含两个结点时，代码是否能正常工作？
* 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！

> 评论区精选
* CPU缓存：CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中。访问数据时会先从CPU缓存开始查找
* LeetCode 对应题目编号：206，141，21，19，876


## 栈

栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为我觉得，相比数组和链表，栈带给我的只有限制，并没有任何优势。那我直接使用数组或者链表不就好了吗？为什么还要用这个“操作受限”的“栈”呢？事实上，从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作 **顺序栈**，用链表实现的栈，我们叫作 **链式栈**。

浏览器的前进后退功能是通过两个栈来实现的。

### 支持动态扩容的顺序栈

尽管链式栈的大小不受限，但要存储 next 指针，内存消耗相对较多。那我们如何基于数组实现一个可以支持动态扩容的栈呢？你还记得，我们在数组那一节，是如何来实现一个支持动态扩容的数组的吗？当数组空间不够时，我们就重新申请一块更大的内存，将原来数组中数据统统拷贝过去。这样就实现了一个支持动态扩容的数组。所以，如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。

### 栈在函数调用中的应用

栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是函数调用栈。我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

### 栈在表达式求值中的应用

编译器就是通过两个栈来实现表达式求值的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

<img src="images/stack-expression.jpg" width="571">

### 栈在括号匹配中的应用

这里也可以用栈来解决。我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。



## 队列



## 递归


## 排序


## 二分查找


## 跳表


## 散列表


## 哈希算法



## 二叉树基础


## 红黑树


## 递归树



## 堆



## 图


## 深度和广度优先搜索


## 字符串匹配基础


## Trie 树


## AC 自动机



## 贪心算法


## 分治算法


## 回溯算法


## 动态规划







