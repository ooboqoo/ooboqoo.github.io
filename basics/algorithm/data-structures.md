# 数据结构

<script>ooboqoo.contentsRegExp = /H[123]/;</script>

## 数组

数组可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。

### 如何实现随机访问

**数组 Array** 是一种 *线性表* 数据结构。它用一组 *连续的内存空间* ，来存储一组具有 *相同类型* 的数据。数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

顾名思义，**线性表** 就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。而与之相对的是 **非线性表**，如二叉树、堆、图等。在非线性表中，数据之间并不是简单的前后关系。

数组有两个限制：连续的内存空间和相同类型的数据。正是因为这两个限制，才有了一个堪称杀手锏的特性：*随机访问*。但有利就有弊，这两个限制导致数组的很多操作变得非常低效，如删除或插入一个数据，为了保证连续性，需要做大量的数据搬移工作。

从数组存储的内存模型上来看，**下标** 最确切的定义应该是 **偏移(offset)**。如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：

```txt
a[k]_address = base_address + k * type_size。
```

### 低效的插入、删除操作

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。

如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，可以直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

```txt
// 当元素顺序无关紧要时，在数组中的某个位置插入一个元素的快捷方法 (这个例子不是很好，干嘛不直接追加到末尾？)
{a, b, c, d, e}  -- 在 a[2] 插入 x --> {a, b, x, d, e, c}
```

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了保证内存的连续性，也需要搬移数据。在某些特殊场景下，我们并不一定非得追求数组中数据的(实时)连续性。我们可以先记录下已经删除的数据，每次删除并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？

### 数组的访问越界问题

我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。这种情况下，一般都会出现莫名其妙的逻辑错误，debug 的难度非常的大。很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统。

如果你是 Java 工程师，几乎天天都在用 `ArrayList`。那它和数组相比，到底有哪些优势呢？如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。
1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 `Object[][] array`；而用容器的话则需要这样定义：`ArrayList<ArrayList<object>> array`。

总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

> 评论区精选

```c
// 在关闭堆栈保护功能时此段代码会无限循环
int main() {
  int i = 0;
  int arr[3] = {0};
  for(; i <= 3; i++) {
    arr[i] = 0;  // i 为 3 时实际执行的是 `i = 0;`
    printf("hello world\n");
  }
}
```

* 在 Linux 进程的内存布局中，栈区在高地址空间，从高向低增长
* 编译器在 64 位操作系统下默认会进行 8 字节对齐
* gcc 有一个编译选项 -fno-stack-protector 用于关闭堆栈保护功能。默认情况下启动了堆栈保护，不管 i 声明在前还是在后，i 都会在数组之后压栈。关闭堆栈保护功能后的压栈顺序为 i a[2] a[1] a[0]



## 链表

### 单链表、循环链表、双向链表

链表结构五花八门，这里重点介绍三种最常见的链表结构，它们分别是：单链表、循环链表和双向链表。

首先来看最简单、最常用的 **单链表**。链表通过指针将一组 *零散的内存块* 串联在一起。其中，我们把内存块称为链表的 **结点**。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。我们把这个记录下个结点地址的指针叫作 **后继指针 next**。链表中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作 **头结点**，把最后一个结点叫作 **尾结点**。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个 **空地址 NULL**，表示这是链表上最后一个结点。与数组一样，链表也支持数据的查找、插入和删除操作。

<img src="images/linked-list.jpg" width="285">

**循环链表** 是一种特殊的单链表。它跟单链表唯一的区别就在尾结点。循环链表的尾结点指针指向链表的头结点。当要处理的数据具有环型结构特点时，就特别适合采用循环链表，如著名的约瑟夫问题。

单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而 **双向链表**，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个 **前驱指针 prev** 指向前面的结点。

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。

#### 双向链表的性能优势

从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。

我们先来看删除操作。在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：删除结点中“值等于某个给定值”的结点；删除给定指针指向的结点。对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！

同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。

除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。

在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛。Java 中的 `LinkedHashMap` 容器就用到了双向链表。实际上，这里有一个更加重要的知识点需要你掌握，那就是 *用空间换时间* 的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用 *以时间换空间* 的设计思路。

### 链表 vs 数组

相比数组，链表是一种稍微复杂一点的数据结构。我们常常会将这两个非常基础的数据结构放到一块来比较。

我们先从 *底层的存储结构* 上来看一看。数组需要一块 *连续的内存空间* 来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组 *零散的内存块* 串联起来使用，所以申请 100MB 大小的链表就没有问题。

数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，*它们插入、删除、随机访问操作的时间复杂度正好相反*。不过，数组和链表的对比，并不能局限于时间复杂度。

我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点。所以，*在链表中插入和删除一个数据是非常快速的*。

但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。所以，*链表随机访问的性能没有数组好*，需要 O(n) 的时间复杂度。

数组简单易用，在实现上使用的是连续的内存空间，*可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高*。而链表在内存中并不是连续存储的，所以对 CPU 缓存不友好，没办法有效预读。

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，*天然地支持动态扩容*，我觉得这也是它与数组最大的区别。

除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以 *内存消耗会翻倍*。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，*容易造成内存碎片*，如果是 Java 语言，就有可能会导致频繁的垃圾回收。

### 链表应用

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。

LRU 缓存淘汰算法就是一个经典的链表应用场景。我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况：
  1. 如果此时缓存未满，则将此结点直接插入到链表的头部；
  2. 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。

除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。

### 如何写出正确的链表代码

* 理解指针或引用的含义
* 警惕指针丢失和内存泄漏
* 利用哨兵简化实现难度
* 重点留意 *边界条件* 处理
* 举例画图，辅助思考
* 多写多练，没有捷径

哨兵应用示例

```c
// 在数组 array 中查找 x 的位置，其中 n 为数组的长度
int find1(int array[], int n, int x) {
  int i = 0;
  while (i < n) {
    if (array[i] == x) return i;
    i++;
  }
  return -1;
}

// 利用哨兵再循环内部省掉了一个判断语句，当 n 很大时这个优化的效果就很客观了
int find2(int array[], int n, int x) {
  int i = 0;
  if (array[n - 1] == x) return n - 1;
  array[n - 1] = x;           // 设置哨兵，确保下面的 while 语句不会出现死循环
  while (array[i] != x) i++;  // 因为上一步设置了哨兵，所以可以省掉一个 i < n 的判断
  return i == n - 1 ? -1 : i;
}
```

软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下能否正确运行。我经常用来检查链表代码是否正确的边界条件有这样几个：
* 如果链表为空时，代码是否能正常工作？
* 如果链表只包含一个结点时，代码是否能正常工作？
* 如果链表只包含两个结点时，代码是否能正常工作？
* 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！

> 评论区精选
* CPU缓存：CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中。访问数据时会先从CPU缓存开始查找
* LeetCode 对应题目编号：206，141，21，19，876



## 栈

*栈是一种操作受限的线性表，只允许在一端插入和删除数据*。栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈叫 **顺序栈**，用链表实现的栈叫 **链式栈**。浏览器的前进后退功能就是通过两个栈来实现的。

我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为我觉得，相比数组和链表，栈带给我的只有限制，并没有任何优势。那我 *为什么要用这个操作受限的栈而不直接使用数组或链表呢？* 从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，使用时就比较不可控，更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选栈这种数据结构。

### 支持动态扩容的顺序栈

尽管链式栈的大小不受限，但要存储 next 指针，内存消耗相对较多。那我们如何基于数组实现一个可以支持动态扩容的栈呢？如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。

### 栈在函数调用中的应用

栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是函数调用栈。我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

### 栈在表达式求值中的应用

编译器就是通过两个栈来实现表达式求值的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

<img src="images/stack-expression.jpg" width="571">

### 栈在括号匹配中的应用

我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。

> 评论区精选
* 内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区
* leecode 上关于栈的题目 20，155，232，844，224，682，496



## 队列

队列最大的特点就是先进先出，主要的两个操作是 *入队 enqueue()* 放一个数据到队列尾部；*出队 dequeue()* 从队列头部取一个元素。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫 **顺序队列**，用链表实现的叫 **链式队列**。队列跟栈一样，也是一种操作受限的线性表数据结构。

### 顺序队列和链式队列

基于数组的实现，队列需要两个指针：`head` 指针 指向队头；`tail` 指针 指向队尾。当 tail 指针移到数组末端时存在数据搬移操作。

基于链表的实现，同样需要两个指针。入队时 `tail->next = new_node; tail = tail->next;` 出队时 `head = head->next`。

### 循环队列

我们刚才用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响。那有没有办法能够避免数据搬移呢？我们来看看循环队列的解决思路。

循环队列是我们这节的重点。要想写出没有 bug 的循环队列实现代码，关键要 *确定好队空和队满的判定条件*。

```c
if (tail == size) tail = 0; // 将数组首尾相连改成循环队列
if (head == tail);  // 队列为空
if ((tail + 1) % size == head);  // 为了实现队满的判断，循环队列会浪费一个数组元素
```

除此之外，我们还讲了几种高级的队列结构，阻塞队列、并发队列，底层都还是队列这种数据结构，只不过在之上附加了很多其他功能。阻塞队列就是入队、出队操作可以阻塞，并发队列就是队列的操作多线程安全。

### 阻塞队列和并发队列

队列这种数据结构很基础，平时的业务开发不大可能从零实现一个队列，甚至都不会直接用到。而一些具有特殊特性的队列应用却比较广泛，比如阻塞队列和并发队列。

**阻塞队列** 其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。你应该已经发现了，上述的定义就是一个“生产者 - 消费者模型”！是的，我们可以使用阻塞队列，轻松实现一个“生产者 - 消费者模型”！

“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。

在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题，那如何实现一个线程安全的队列呢？线程安全的队列我们叫作 **并发队列**。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。在实战篇讲 Disruptor 的时候，我会再详细讲并发队列的应用。

### 队列的应用

CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是固定的。当固定大小的线程池没有空闲线程时，线程池该如何处理新的任务请求？

我们一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。那如何存储排队的请求呢？我们希望公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合用来存储排队请求。

基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。

而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

除了前面讲到队列应用在线程池请求排队的场景之外，队列可以应用在任何有限资源池中，用于排队请求，比如数据库连接池等。实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

在很多偏底层系统、框架、中间件的开发中，队列都起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

> 评论区精选
* 循环队列的长度设定需要对并发数据有一定的预测，否则会丢失太多请求。
* 循环队列中浪费了一个数组元素，可以通过定义一个记录队列大小的值 size 来判断是否队满。个人评：没前面的好就是了





## 跳表


## 散列表


## 哈希算法



## 二叉树基础


## 红黑树


## 递归树



## 堆



## 图


## 深度和广度优先搜索


## 字符串匹配基础


## Trie 树


## AC 自动机



## 贪心算法


## 分治算法


## 回溯算法


## 动态规划







