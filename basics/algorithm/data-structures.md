# 数据结构

<script>ooboqoo.contentsRegExp = /H[123]/;</script>

* 数组 Array
  - 特点：连续的内存空间
  - 优点：随机访问 + CPU缓存
  - 缺点：插入、删除操作效率低
* 链表 Linked List
  - 特点：零散的内存块
  - 优点：插入和删除快; 天然支持动态扩容
  - 缺点：查询效率低; 容易造成内存碎片
* 栈 Stack
  - 顺序栈、链式栈
  - 实现： `push()` `pop()`
  - 适用场景：函数调用栈; 编译器中表达式求值; 括号匹配
* 队列 Queue
  - 分类：顺序队列、链式队列；循环队列; 阻塞队列、并发队列
  - 实现：指针 `head` `tail`; 结构 `next`; 操作 `enqueue()` `dequeue()`
  - 适用场景：适用于大部分资源有限的场景，如线程池请求排队
* 跳表 Skip List
  - 特点：在链表的基础上新增若干索引链表，将查询效率由 O(n) 提升到 O(logn); 用空间换时间
  - 实现：索引动态更新的核心是 特定的随机函数
* 散列表 Hash Table
  - 特点：散列表用的是数组支持按照下标随机访问数据的特性，故查询效率 O(1)
  - 适用场景：单词拼写检查; LRU缓存的索引
* 二叉树
  - 特点：
  - 优点：
  - 缺点：
  - 适用场景：
* 堆
  - 特点：建堆 O(n)，求 Top K 问题的最坏时间复杂度为 O(nlogK)，比排序的 O(nlogn) 快很多
  - 适用场景：热门榜（Top N 关键词）、优先级队列、求中位数
  - 备考：要会基于现有数组进行建堆操作
* 图
  - 特点：
  - 优点：
  - 缺点：
  - 适用场景：
* Trie树
  - 特点：
  - 优点：
  - 缺点：
  - 适用场景：


## 数组 Array

数组可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。

### 如何实现随机访问

**数组 Array** 是一种 *线性表* 数据结构。它用一组 *连续的内存空间* ，来存储一组具有 *相同类型* 的数据。数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

顾名思义，**线性表** 就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。而与之相对的是 **非线性表**，如二叉树、堆、图等。在非线性表中，数据之间并不是简单的前后关系。

数组有两个限制：连续的内存空间和相同类型的数据。正是因为这两个限制，才有了一个堪称杀手锏的特性：*随机访问*。但有利就有弊，这两个限制导致数组的很多操作变得非常低效，如删除或插入一个数据，为了保证连续性，需要做大量的数据搬移工作。

从数组存储的内存模型上来看，**下标** 最确切的定义应该是 **偏移(offset)**。如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：

```txt
a[k]_address = base_address + k * type_size。
```

### 低效的插入、删除操作

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。

如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，可以直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

```txt
// 当元素顺序无关紧要时，在数组中的某个位置插入一个元素的快捷方法
{a, b, c, d, e}  -- 在 a[2] 插入 x --> {a, b, x, d, e, c}
```

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了保证内存的连续性，也需要搬移数据。在某些特殊场景下，我们并不一定非得追求数组中数据的(实时)连续性。我们可以先记录下已经删除的数据，每次删除并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？

### 数组的访问越界问题

我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。这种情况下，一般都会出现莫名其妙的逻辑错误，debug 的难度非常的大。很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统。

如果你是 Java 工程师，几乎天天都在用 `ArrayList`。那它和数组相比，到底有哪些优势呢？如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。
1. Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 `Object[][] array`；而用容器的话则需要这样定义：`ArrayList<ArrayList<Object>> array`。

总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

> 评论区精选

```c
// 在关闭堆栈保护功能时此段代码会无限循环
int main() {
  int i = 0;
  int arr[3] = {0};
  for(; i <= 3; i++) {
    arr[i] = 0;  // i 为 3 时实际执行的是 `i = 0;`
    printf("hello world\n");
  }
}
```

* 在 Linux 进程的内存布局中，栈区在高地址空间，从高向低增长
* 编译器在 64 位操作系统下默认会进行 8 字节对齐
* gcc 有一个编译选项 -fno-stack-protector 用于关闭堆栈保护功能。默认情况下启动了堆栈保护，不管 i 声明在前还是在后，i 都会在数组之后压栈。关闭堆栈保护功能后的压栈顺序为 i a[2] a[1] a[0]



## 链表 Linked List

### 单链表、循环链表、双向链表

链表结构五花八门，这里重点介绍三种最常见的链表结构，它们分别是：单链表、循环链表和双向链表。

singly linked list 单链表;  doubly linked list 双向链表;  circular linked list 循环链表  

首先来看最简单、最常用的 **单链表**。链表通过指针将一组 *零散的内存块* 串联在一起。其中，我们把内存块称为链表的 **结点**。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。我们把这个记录下个结点地址的指针叫作 **后继指针 next**。链表中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作 **头结点**，把最后一个结点叫作 **尾结点**。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个 **空地址 NULL**，表示这是链表上最后一个结点。与数组一样，链表也支持数据的查找、插入和删除操作。

<img src="images/algorithms/linked-list.jpg" width="285">

**循环链表** 是一种特殊的单链表。它跟单链表唯一的区别就在尾结点。循环链表的尾结点指针指向链表的头结点。当要处理的数据具有环型结构特点时，就特别适合采用循环链表，如著名的约瑟夫问题。

单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而 **双向链表**，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个 **前驱指针 prev** 指向前面的结点。

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。

#### 双向链表的性能优势

从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。

我们先来看删除操作。在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：删除结点中“值等于某个给定值”的结点；删除给定指针指向的结点。对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！

同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。

除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。

在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛。Java 中的 `LinkedHashMap` 容器就用到了双向链表。实际上，这里有一个更加重要的知识点需要你掌握，那就是 *用空间换时间* 的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用 *以时间换空间* 的设计思路。

### 链表 vs 数组

相比数组，链表是一种稍微复杂一点的数据结构。我们常常会将这两个非常基础的数据结构放到一块来比较。

我们先从 *底层的存储结构* 上来看一看。数组需要一块 *连续的内存空间* 来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组 *零散的内存块* 串联起来使用，所以申请 100MB 大小的链表就没有问题。

数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，*它们插入、删除、随机访问操作的时间复杂度正好相反*。不过，数组和链表的对比，并不能局限于时间复杂度。

我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点。所以，*在链表中插入和删除一个数据是非常快速的*。

但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。所以，*链表随机访问的性能没有数组好*，需要 O(n) 的时间复杂度。

数组简单易用，在实现上使用的是连续的内存空间，*可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高*。而链表在内存中并不是连续存储的，所以对 CPU 缓存不友好，没办法有效预读。

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，*天然地支持动态扩容*，我觉得这也是它与数组最大的区别。

除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以 *内存消耗会翻倍*。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，*容易造成内存碎片*，如果是 Java 语言，就有可能会导致频繁的垃圾回收。

### 链表应用

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。

LRU 缓存淘汰算法就是一个经典的链表应用场景。我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况：
  1. 如果此时缓存未满，则将此结点直接插入到链表的头部；
  2. 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。

除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。

### 如何写出正确的链表代码

* 理解指针或引用的含义
* 警惕指针丢失和内存泄漏
* 利用哨兵简化实现难度
* 重点留意 *边界条件* 处理
* 举例画图，辅助思考
* 多写多练，没有捷径

哨兵应用示例

```c
// 在数组 array 中查找 x 的位置，其中 n 为数组的长度
int find1(int array[], int n, int x) {
  int i = 0;
  while (i < n) {
    if (array[i] == x) return i;
    i++;
  }
  return -1;
}

// 利用哨兵再循环内部省掉了一个判断语句，当 n 很大时这个优化的效果就很客观了
int find2(int array[], int n, int x) {
  int i = 0;
  if (array[n - 1] == x) return n - 1;
  array[n - 1] = x;           // 设置哨兵，确保下面的 while 语句不会出现死循环
  while (array[i] != x) i++;  // 因为上一步设置了哨兵，所以可以省掉一个 i < n 的判断
  return i == n - 1 ? -1 : i;
}
```

软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下能否正确运行。我经常用来检查链表代码是否正确的边界条件有这样几个：
* 如果链表为空时，代码是否能正常工作？
* 如果链表只包含一个结点时，代码是否能正常工作？
* 如果链表只包含两个结点时，代码是否能正常工作？
* 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！

> 评论区精选
* CPU缓存：CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中。访问数据时会先从CPU缓存开始查找
* LeetCode 对应题目编号：206，141，21，19，876



## 栈 Stack

*栈是一种操作受限的线性表，只允许在一端插入和删除数据*。栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈叫 **顺序栈**，用链表实现的栈叫 **链式栈**。浏览器的前进后退功能就是通过两个栈来实现的。

我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为我觉得，相比数组和链表，栈带给我的只有限制，并没有任何优势。那我 *为什么要用这个操作受限的栈而不直接使用数组或链表呢？* 从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，使用时就比较不可控，更容易出错。当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选栈这种数据结构。

### 支持动态扩容的顺序栈

尽管链式栈的大小不受限，但要存储 next 指针，内存消耗相对较多。那我们如何基于数组实现一个可以支持动态扩容的栈呢？如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。

### 栈在函数调用中的应用

栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是函数调用栈。我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。

### 栈在表达式求值中的应用

编译器就是通过两个栈来实现表达式求值的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

<img src="images/algorithms/stack-expression.jpg" width="571">

### 栈在括号匹配中的应用

我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。

> 评论区精选
* 内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区
* leecode 上关于栈的题目 20，155，232，844，224，682，496



## 队列 Queue

队列最大的特点就是先进先出，主要的两个操作是 *入队 enqueue()* 放一个数据到队列尾部；*出队 dequeue()* 从队列头部取一个元素。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫 **顺序队列**，用链表实现的叫 **链式队列**。队列跟栈一样，也是一种操作受限的线性表数据结构。

### 顺序队列和链式队列

基于数组的实现，队列需要两个指针：`head` 指针 指向队头；`tail` 指针 指向队尾。当 tail 指针移到数组末端时存在数据搬移操作。

基于链表的实现，同样需要两个指针。入队时 `tail->next = new_node; tail = tail->next;` 出队时 `head = head->next`。

### 循环队列

我们刚才用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响。那有没有办法能够避免数据搬移呢？我们来看看循环队列的解决思路。

循环队列是我们这节的重点。要想写出没有 bug 的循环队列实现代码，关键要 *确定好队空和队满的判定条件*。

```c
if (tail == size) tail = 0; // 将数组首尾相连改成循环队列
if (head == tail);  // 队列为空
if ((tail + 1) % size == head);  // 为了实现队满的判断，循环队列会浪费一个数组元素
                                 // tail 指向的那个空格是不能放数据的
```

除此之外，我们还讲了几种高级的队列结构，阻塞队列、并发队列，底层都还是队列这种数据结构，只不过在之上附加了很多其他功能。阻塞队列就是入队、出队操作可以阻塞，并发队列就是队列的操作多线程安全。

### 阻塞队列和并发队列

队列这种数据结构很基础，平时的业务开发不大可能从零实现一个队列，甚至都不会直接用到。而一些具有特殊特性的队列应用却比较广泛，比如阻塞队列和并发队列。

**阻塞队列** 其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。你应该已经发现了，上述的定义就是一个“生产者 - 消费者模型”！是的，我们可以使用阻塞队列，轻松实现一个“生产者 - 消费者模型”！

“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。

在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题，那如何实现一个线程安全的队列呢？线程安全的队列我们叫作 **并发队列**。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。在实战篇讲 Disruptor 的时候，我会再详细讲并发队列的应用。

### 队列的应用

CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是固定的。当固定大小的线程池没有空闲线程时，线程池该如何处理新的任务请求？

我们一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。那如何存储排队的请求呢？我们希望公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合用来存储排队请求。

基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。

而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

除了前面讲到队列应用在线程池请求排队的场景之外，队列可以应用在任何有限资源池中，用于排队请求，比如数据库连接池等。实际上，对于大部分*资源有限的场景*，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

在很多偏底层系统、框架、中间件的开发中，队列都起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

> 评论区精选
* 循环队列的长度设定需要对并发数据有一定的预测，否则会丢失太多请求。
* 循环队列中浪费了一个数组元素，可以通过定义一个记录队列大小的值 size 来判断是否队满。个人评：没前面的好就是了



## 跳表 Skip List

> 查询时间复杂度 O(n) -> O(logn); 因为需要建立索引，空间复杂度为 O(n)

二分查找底层依赖的是数组随机访问的特性，所以只能用数组来实现。其实只要对链表稍加改造就可以支持类似“二分”的查找算法，这种改造之后的数据结构叫做 **跳表 Skip List**。

跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速地插入、删除、查找操作，甚至可以替代红黑树。Redis 中的有序集合 Sorted Set 就是用跳表实现的。

<img src="images/algorithms/skip-list.webp" width="571">

跳表的操作
* 查询、插入、删除 都很简单
* 索引的动态更新的核心是 特定的*随机函数* （对比：红黑树、AVL树 这类平衡二叉树通过 左右旋 的方式保持左右树的大小平衡）

往跳表插入数据的时候，通过一个随机函数来决定将这个节点插入到哪几级索引中。比如，随机函数生成了值 K，那我们就将这个结点添加到 1~K 级别索引中。

跳表 VS 红黑树
* 跳表实现更简单
* 跳表更加灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗
* “按照区间来查找数据” 这个操作，跳表效率比红黑树高



## 散列表(Hash表) Hash Table

散列表用的是数组支持按照下标随机访问数据的特性(时间复杂度为 O(1))，所以*散列表其实就是数组的一种扩展*。

我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中应用下标的位置。

<img src="images/algorithms/hash-table.webp" width="571">

散列函数设计的基本要求
1. 散列函数计算得到的散列值是一个非负整数
2. 如果 key1 == key2，那 hash(key1) == hash(key2)
3. 如果 key1 != key2，那 hash(key1) != hash(key2)  // 注

第三点在现实情况下几乎不可能达成，像业界著名的 MD5 SHA CRC 等哈希算法 也无法完全避免这种散列冲突。

常用的散列冲突解决方法有两类：开放寻址法 open addressing 和 链表法 chaining

<img src="images/algorithms/hash-table-chaining.webp" width="285">

英文拼写检查，因为20万英文单词也就2MB大小，所以完全可以全部加载到内存，用删列表来存储整个英文单词词典。拿输入的单词去散列表中查找，找到就说明拼写正确，否则拼写有误。

### 散列表和链表组合使用

LRU 缓存
* 链表实现的 LRU 缓存淘汰算法的时间复杂度为 O(n)，再搭配上散列表就可以将时间复杂度降为 O(1)
* 链表负责增加、删除一个数据，散列表 `Map<Value, ListNode>` 负责查找数据



## 树

### 树基础

树相关的一些基本概念

* 节点：根节点、叶节点; 父节点、子节点、兄弟节点
* 节点的高度 Height：节点到叶子节点的最长路径（边数）
* 树的高度：根节点的高度
* 节点深度 Depth：根节点到这个节点所经历的边的个数
* 节点的层数 Level：节点的深度 + 1

<img src="images/algorithms/tree-concept.webp" width="285">

### 二叉树基础

二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。二叉树是最常用的树。

* 下图中 1 为普通二叉树
* 下图中 2 为 **满二叉树**：叶子节点全都在最底层，除了叶子节点外，每个节点都有左右两个子节点
* 下图中 3 为 **完全二叉树**：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层节点都是满的

<img src="images/algorithms/binary-tree.webp" width="285">

### 二叉树的存储

存储一棵二叉树有两种方法，一种是基于指针或者引用的二叉*链式存储法*，一种是基于数组的*顺序存储法*。

基于数组的顺序存储法，为了计算方便，*根节点存储在下标 i=1 的位置*，这样后续左子节点分别存到 2 4 8 ... 2xi 的位置。采用这种存储方式，*完全二叉树能够充分利用数组空间*，但如果是不完全二叉树，则会浪费较多空间。

<img src="images/algorithms/binary-tree-array.webp" width="571">

### 二叉树的遍历

如何将所有节点都遍历打印出来呢？经典的方法有三种，前序遍历、中序遍历和后序遍历。

<img src="images/algorithms/binary-tree-iterate.webp" width="571">

```java
void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印root节点
  preOrder(root->left);
  preOrder(root->right);
}

void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印root节点
  inOrder(root->right);
}

void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印root节点
}
```

### 二叉查找树 Binary Search Tree

**二叉查找树**也叫**二叉搜索树**，是二叉树中最常用的一种类型。它最大的特点就是支持动态数据集合的快速插入、删除、查找操作。

*二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值都小于这个节点的值，而右子树节点的值都大于这个节点的值*。

二叉查找树的查找、插入操作都比较简单，但它的删除操作相对较复杂。当然，删除操作还有种非常简单取巧的方法，就是仅添加删除标记不实际删除。

如果要进行删除操作，需要分三种情况处理
1. 如果要删除的节点没有子节点，直接删
2. 如果要删除的节点只有一个节点，将它的节点挂到它的父节点就行
3. 如果有两个子节点，则需要将右子树的最小节点提上来替换本节点

二叉查找树还有一个重要特性，就是 *中序遍历二叉查找树，可以输出有序的数据序列*，时间复杂度是 O(n)，非常高效。

### 平衡二叉查找树 Self-balancing Binary Search Tree

二叉查找树在频繁的动态更新过程中可能会出现树的高度远大于 log<sub>2</sub>n 的情况，从而导致操作效率下降，极端情况下会退化为链表。要解决这个复杂度退化的问题，需要设计一种平衡二叉查找树。

**严格平衡二叉树**的定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于1。  
实际工程应用上的“平衡”要求没那么严格，只要*让整棵树左右看起来比较对称，不要出现左子树很高、右子树很矮的情况*就行。

最早出现的**平衡二叉查找树**是 AVL树，它是一种严格平衡二叉查找树。另外还有 树堆 Treap、伸展树 Splay Tree 等，但都应用不多。*实际最常用的是红黑树，红黑树甚至可看成是平衡二叉查找树的代名词*。

#### 平衡二叉查找树 VS 散列表

散列表的插入、删除、查找操作的时间复杂度可以做到O(1)，而二叉查找树在平衡的情况下操作时间复杂度才到 O(logn)，那我啥还要用二叉查找树呢？

1. 二叉查找树通过中序遍历可以在 O(n) 时间复杂度内输出*有序的数据系列*，而散列表则需要进行排序 O(nlogn)
2. 散列表(底层为数组)扩容耗时多，且当遇到散列冲突时*性能不稳定*，而平衡二叉查找树的性能稳定在 O(logn)
3. 散列表的散列冲突 + 哈希函数耗时，实际查找速度不一定比 O(logn) 快
4. 散列表的构造比二叉查找树要复杂：散列表要考虑散列函数的设计、冲突解决办法、扩容、缩容等；而二叉查找树只需要解决平衡性这个问题，且方案比较成熟固定（红黑树）

### 红黑树 Red-Black Tree / R-B Tree

<img src="images/algorithms/red-black-tree.jpg" width="210">

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 2log<sub>2</sub>n (相较严格平衡树的 log<sub>2</sub>n 仅大了一倍)，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。

#### 实现一个红黑树

> 红黑树稳定高效，但实现起来太难。靠谱的面试官不会让你手写红黑树，如果业务中真要自己实现，更倾向用跳表来替代。

顾名思义，红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：
* 节点有两种类型：红色 或 黑色
* *根节点是黑色的*；
* 每个叶子节点都是黑色的空节点（NIL），也就是说，*叶子节点不存储数据*；// 为了简化代码实现而设置的规则
* *任何相邻的节点都不能同时为红色*，也就是说，红色节点是被黑色节点隔开的；
* 每个节点，从该节点到达其可达叶子节点的*所有路径，都包含相同数目的黑色节点*； // 平衡就是靠这条规则

派生特性
* Nodes require one storage bit to keep track of color
* The longest path (root to farthest NIL) is no more than twice the length of the shortest path (root to nearest NIL) // Shortest path: all black nodes; Longest path: alternating red and black

实现红黑树的基本思想：我们玩的魔方的复原解法是有固定算法的：遇到哪几面是什么样子，对应就怎么转几下。*红黑树的平衡过程跟魔方复原非常神似，每种特定的节点排布都有对应的调整规则*，按照这些固定规则来操作，就能将一个非平衡的红黑树调整成平衡的。

`Search()` 操作正常进行就行，而 `Insert()` `Remove()` 操作则涉及 rotation 操作，后续具体操作原理略...
* **左旋** left-rotate 全称叫 围绕某个节点的左旋
* **右旋** right-rotate 全称叫 围绕某个节点的右旋

<img src="images/algorithms/red-black-tree-adjust.webp" width="571">

### 递归树 Recursion Tree

递归代码的时间复杂度分析起来很麻烦，我们可以借助树这种数据结构来分析递归算法的时间复杂度。

递归的思想就是将大问题分解为小问题来求解，我们把一层层的分解过程画成图，它其实就是一棵树，我们叫它 **递归树**。



## 堆 Heap

只要满足以下两个点的树就是堆
* 堆是一个完全二叉树
* 堆中的每个节点的值必须大于等于（或小于等于）其子树中每个节点的值
  - 每个节点的值都大于等于子树中节点值的堆 叫 **大顶堆**
  - 每个节点的值都小于等于子树中节点值的堆 叫 **小顶堆**

> 评论区精选
> * 这种数据结构和内存模型中的堆有什么关系：完全是两个东西

### 实现一个堆

<img src="images/algorithms/heap.webp" width="571">

从上图中我们可以看到，数组中下标为 `i` 的节点，左子节点的下标为 `i*2`，右子节点的下标为 `i*2+1`，父节点的下标为 `i/2`

往大顶堆中*插入*一个元素：在堆最后插入新元素，然后进行顺序调整（即 **堆化 heapify**）。*堆化非常简单，就是顺着节点所在路径，向上或者向下，对比，然后交换*。（这个操作决定了：*大顶堆只能确定堆顶元素是最大的，第二大的位置就不确定了*，在 2 3 下标中找，第三大的位置要对比的元素就更多了）

*删除*大顶堆的堆顶元素：第一种思路，删除堆顶元素然后从上往下找替补元素，操作完会导致不满足完全二叉树的特征。第二种思路，*把最后一个元素拿到顶上，然后再自顶向下堆化*，就解决了刚才的问题。

```ts
class MaxHeap {
  /** array, store data from index 1 */
  #arr: number[];
  #capacity: number;
  #count: number;

  constructor(capacity: number) {
    this.#capacity = capacity;
    this.#arr = Array(capacity + 1);
    this.#count = 0;
  }

  insert(data: number) {
    if (this.#count >= this.#capacity) return;
    this.#count++;
    this.#arr[this.#count] = data;
    let i = this.#count;
    while (i / 2 > 0 && this.#arr[i] > this.#arr[i / 2]) {
      swap(this.#arr, i, i / 2);
      i = i / 2;
    }
    // console.log(this.#arr);
  }

  removeMax() {
    if (this.#count === 0) return;
    this.#arr[1] = this.#arr[this.#count]; // replace root with last element
    this.#count--;
    while (true) {
      let i = 1;
      let maxPos = i;
      if (i * 2 <= this.#count && this.#arr[i * 2] > this.#arr[maxPos]) maxPos = i * 2;
      if (i * 2 + 1 <= this.#count && this.#arr[i * 2 + 1] > this.#arr[maxPos]) maxPos = i * 2 + 1;
      if (maxPos === i) break;
      swap(this.#arr, i, maxPos);
      i = maxPos;
    }
  }
}

function swap(arr: number[], i: number, j: number) {
  [arr[i], arr[j]] = [arr[j], arr[i]];
}
```

### 堆排序

堆这种数据结构的应用场景非常多，最经典的莫过于堆排序。堆排序是一种原地的、时间复杂度为 O(nlogn) 的排序算法。

堆排序的过程大致可分为 建堆 和 排序 两个过程。

#### 建堆

第一种建堆的思路是利用上面讲的插入操作，逐个添加新元素。而这里要讲第二种思路，*从后往前逐个处理节点（即，从下往上建堆），每处理一个节点进行一次从上往下的堆化*。

每个节点堆化的时间复杂度为 O(logn)，那 n/2 + 1 个节点的堆化时间复杂度就是 O(nlogn)，实际我们还可以通过推导得出更精确的时间复杂度，为 O(n)。

```c
private static void buildHeap(int[] a, int n) {
  // 只对下标为 [1, n/2] 的数据进行堆化
  // 下标 [n/2+1, n] 的节点是叶子节点，不需要堆化
  // [1, n/2] 的数据是从后往前堆化的，可实现原地堆化
  for (int i = n/2; i >= 1; --i) {  // i=n/2 是第一个非叶子节点 // 从后往前逐个处理节点，即，从下往上建堆
    heapify(a, n, i);                                        // 每处理一个节点进行一次从上往下的堆化
  }
}

// 从上往下堆化      go container/heap 中直接用 up down 来命名 向上 和 向下 堆化
private static void heapify(int[] a, int n, int i) {
  while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
  }
}
```

#### 排序

建堆之后，数组中的数据已经按照大顶堆的特性来组织了。数组中第一个元素就是最大的元素。我们把它跟最后一个元素交换，就完成了第 n 个元素的排序。这个过程有点类似于上面的「删除堆顶元素」。

```c
// n表示数据的个数，数组a中的数据从下标1到n的位置。
public static void sort(int[] a, int n) {
  buildHeap(a, n);
  int k = n;
  while (k > 1) {
    swap(a, 1, k);
    --k;
    heapify(a, k, 1);
  }
}
```

#### 堆排序 VS 快速排序

两者都不是稳定排序，排序过程中的位置交换会打乱原有顺序

实际开发中，快速排序要比堆排序性能好，原因有二
* 快速排序访问数据是局部顺序访问，利于 CPU 缓存；而堆排序中的堆化，是 i=1, 2, 4, 8 这样跳着访问的
* 堆排序比快速排序交换次数多。排序中有两个概念：有序度和逆序度，排序的两个基本操作是：比较和交换。快速排序数据交换的次数不会比逆序度多。而堆排序的第一步要建堆，建堆过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。


### 优先级队列

队列的最大特性就是先进先出，不过优先级队列的出队顺序是按照优先级来的，优先级最高的先出队。

优先级队列的实现方法很多，但用堆是最直接、高效的。一个堆就可以看作是优先级队列，很多时候他们只是概念上的区分而已。

优先级队列的应用场景非常多，后面要讲的很多数据结构和算法都要依赖它，如：赫夫曼编码、最短路径、最小生成树算法等等。

应用示例：合并有序小文件、高性能定时器

### 求 Top K 问题

求 Top K 问题可抽象成两类：针对静态数据集合求值，和针对动态数据集合求值

针对静态数据，在一个包含 n 个数据的数组中寻找前 K 大数据，我们可以维护一个大小为 K 的小顶堆。遍历数组 O(n)，一次堆化操作的时间复杂度 O(logK)，*最坏的情况下时间复杂度也只有 O(nlogK)*

对于动态数据，每次求值都重新计算的话，时间复杂度是 O(nlogK)，但实际我们可以一直维护一个 K 大小的小顶堆。当有数据被添加到集合时，只需要拿它跟堆顶元素对比，如果比堆顶元素大，就插入，否则不用处理。

### 求中位数

求中位数实际上还有很多变形，比如求 99 百分位数据、90 百分位数据等，处理的思路都是一样的，即利用两个堆，一个大顶堆，一个小顶堆，随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。




## 图 Graph

涉及图的算法有很多，也非常复杂，比如图的搜索、最短路径、最小生成树、二分图 等等。

树中的元素我们称为节点，图中的元素我们叫 **顶点 vertex**。每个顶点可以与任意其他顶点建立连接关系，这种连接关系叫 **边 edge**。每个顶点跟其他顶点相连接的边的条数我们叫 **顶点的度 degree**。

边还可以有方向，这种边有方向的图叫 **有向图**，边没有方向的图叫 **无向图**。在有向图中，度又分为 **入度 In-degree** 和 **出度 Out-degree**。顶点的入度表示有多少条边指向这个顶点，顶点的出度表示有多少条边是以这个顶点为起点指向其他顶点。

举个现实中微博的例子，「每个人」就是一个「顶点」，「每个关注」就是一条「有方向的边」，「入度」就表示有多少「粉丝」，「出度」就表示「关注了多少人」。

而向 QQ 软件，还存在「亲密度」这样的功能，这时就要用到 **带权图 weighted graph**，每条边都有一个 **权重 weight**，我们可以通过这个权重来表示 QQ 好友间的亲密度。

图最直观的一种存储方法就是 **邻接矩阵 Adjacency Matrix**。邻接矩阵存储方法的缺点是比较浪费空间，但优点是查询效率高，而且方便矩阵运算。

> adjacent  _/əˈdʒeɪsənt/_ adj. 邻近的,毗连的

<img src="images/algorithms/graph-adjacency-matrix.webp" width="571">

图的另一种存储方法是 **邻接表 Adjacency List**，邻接表很像散列表，每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。尽管邻接表的存储方式比较节省存储空间，但链表不方便查找，所以查询效率没有邻接矩阵存储方式高。针对这个问题，邻接表还有改进升级版，即，将链表换成更加高效地动态数据结构，比如平衡二叉查找树、跳表、散列表 等。

```cpp
// 无向图
public class Graph {
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表

  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }

  // 无向图一条边存两次
  public void addEdge(int s, int t) {
    adj[s].add(t);
    adj[t].add(s);
  }
}
```

解答开篇的问题，如何存储微博、微信等社交网络中好友关系...(比较有参考意义，详见 [article/70537](https://time.geekbang.org/column/article/70537))

### 深度和广度优先搜索

在社交网络中，有一个 六度分割理论，具体是说，你与世界上的另一个人间隔的关系不会超过六度，也就是说平均只需要六步就可以联系到任何两个互不相识的人。今天的开篇问题是，「如何找出某个用户的所有三度好友关系(含一度、二度)」。

算法是作用于具体数据结构之上的，深度优先搜索算法和广度优先搜索算法都是基于图这种数据结构的。这是因为图这种数据结构的表达能力很强，大部分涉及搜索的场景都可以抽象成「图」。

图上的搜索算法，最直接的理解就是，从图中找出从一个顶点出发到另一个顶点的路径。具体方法有很多，不如今天要讲的两种最简单、最暴力的深度优先和广度优先搜索，另外还有 `A*` `IDA*` 等启发式搜索算法。

广度优先和深度优先搜索的复杂度：*时间复杂度 O(E)* 边的条数；*空间复杂度 O(V)* 顶点的个数。

#### 广度优先搜索 BFS

**广度优先搜索** (Breadth-First-Search)，简称 **BFS** 其实就是一种地毯式层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。尽管广度优先搜索的原理简单，但代码实现还是稍微有点复杂。

```cpp
public void bfs(int s, int t) {
  if (s == t) return;
  // 用来记录已经被访问的顶点，用来避免顶点被重复访问
  boolean[] visited = new boolean[v];
  // 一个队列，用来存储已经被访问、但相连的顶点还没有被访问的顶点
  visited[s]=true;
  Queue<Integer> queue = new LinkedList<>();
  queue.add(s);
  // 用来记录搜索路径。当我们从顶点 s 开始，广度优先搜索到顶点 t 后，prev 数组中存储的就是搜索的路径
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  while (queue.size() != 0) {
    int w = queue.poll();
   for (int i = 0; i < adj[w].size(); ++i) {
      int q = adj[w].get(i);
      if (!visited[q]) {
        prev[q] = w;
        if (q == t) {
          print(prev, s, t);
          return;
        }
        visited[q] = true;
        queue.add(q);
      }
    }
  }
}

private void print(int[] prev, int s, int t) { // 递归打印s->t的路径
  if (prev[t] != -1 && t != s) {
    print(prev, s, prev[t]);
  }
  System.out.print(t + " ");
}
```

最坏情况下，终止顶点 t 离起始顶点 s 很远，需要遍历完整个图才能找到。这个时候，每个顶点都要进出一遍队列，每个边也都会被访问一次，所以，广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数。当然，对于一个连通图来说，也就是说一个图中的所有顶点都是连通的，E 肯定要大于等于 V-1，所以，广度优先搜索的时间复杂度也可以简写为 O(E)。

广度优先搜索的空间消耗主要在几个辅助变量 visited 数组、queue 队列、prev 数组上。这三个存储空间的大小都不会超过顶点的个数，所以空间复杂度是 O(V)。

#### 深度优先搜索 DFS

**深度优先搜索** (Depth-First-Search)，简称 **DFS**。最直观的例子就是“走迷宫”。假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略。


## 字符串匹配基础

* 单模式串匹配算法
  - BF 算法 和 RK 算法：简单
  - BM 算法 和 KMP 算法：难理解但高效
* 多模式串匹配算法

### BF 算法

**BF 算法** 中的 BF 是 **Brute Force** 的缩写，中文叫 **暴力匹配算法**，也叫 **朴素匹配算法**

主串 和 模式串：比如我们在字符串A中查找字符串B，那字符串A就是 **主串**，字符串B就是 **模式串**。

作为最简单、最暴力的字符串匹配算法，BF 算法的思想可以用一句话来概括，那就是，我们在主串中，检查起始位置分别是 0、1、2....n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。

在极端情况下，比如主串是“aaaaa....aaaaaa”（省略号表示有很多重复的字符 a），模式串是“aaaaab”。我们每次都比对 m 个字符，要比对 n-m+1 次，所以，这种算法的 *最坏情况时间复杂度是 O(n\*m)*。

尽管理论上，BF 算法的时间复杂度很高 O(n\*m)，但实际的开发中却是一个比较常用的字符串匹配算法，原因有两点：
* 实际大部分情况下，模式串和主串的长度都不会太长
* 算法思想简单，代码实现也非常简单。简单意味着不容易出错

**RK 算法** 是借助哈希算法对 BF 算法进行改造，即对每个子串分别求哈希值，然后拿子串的哈希值与模式串的哈希值比较，减少了比较的时间。所以，理想情况下，RK 算法的时间复杂度是 O(n)，跟 BF 算法相比，效率提高了很多。不过这样的效率取决于哈希算法的设计方法，如果存在冲突的情况下，时间复杂度可能会退化。

### BM 算法

对于工业级的软件开发来说，我们希望算法尽可能高效，并且在极端情况下，性能也不要退化太严重。

**BM 算法 Boyer-Moore** 是一种非常高效的字符串匹配算法，有实验统计，它的性能是著名的 KMP 算法 的3到4倍。但 BM 算法的原理很复杂。

BM 算法核心思想是，利用模式串本身的特点，在模式串中某个字符与主串不能匹配的时候，*将模式串往后多滑动几位*，以此来减少不必要的字符比较，提高匹配的效率。BM 算法构建的规则有两类，坏字符规则和好后缀规则。好后缀规则可以独立于坏字符规则使用。因为坏字符规则的实现比较耗内存，为了节省内存，我们可以只用好后缀规则来实现 BM 算法。

## Trie 树

<img src="images/algorithms/trie.webp" width="571">

Trie 树最有优势的是查找前缀匹配的字符串，比如搜索引擎中关键词提示功能就是 Trie 树比较经典的应用场景。



## AC 自动机







